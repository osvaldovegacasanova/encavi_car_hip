# An谩lisis y Clasificaci贸n de Enfermedad Cardiaca e Hipertensi贸n - ENCAVI 2015-2016 ┖

Proyecto realizado usando datos p煤blicos de la Encuesta Nacional de Calidad de Vida y Salud ENCAVI 2015-16 realizada por el Departamento de Epidemiolog铆a, Ministerio de Salud de Chile con el objetivo de detectar patrones conductuales que afectan la probabilidad de desarrollo de enfermedades .

Se ha hecho una selecci贸n de variables para predecir la presencia de enfermedad cardiaca e hipertensi贸n mediante un modelo de Random Forest, aplicando t茅cnicas de balanceo y validaci贸n cruzada. det

El dataset a cargar es una reducci贸n de variables de la encuesta original (ENCAVI 2015-2016) encontrada en 
[https://epi.minsal.cl/resultados-encuestas/](https://epi.minsal.cl/wp-content/uploads/2017/06/Resultados_Abril2017_ENCAVI_2015-16_Depto_Epidemiolog%C3%ADa_MINSAL.pdf)



##  Flujo del Proyecto

Este notebook sigue una estructura modular para procesar, analizar y modelar datos de salud de la encuesta ENCAVI. A continuaci贸n se detalla cada etapa del flujo de trabajo:

### 1. **Importaci贸n de Librer铆as**
Se cargan librer铆as clave para an谩lisis de datos, visualizaci贸n, modelado (scikit-learn), y balanceo de clases (SMOTE desde `imbalanced-learn`).

### 2. **Configuraci贸n Global**
Se definen par谩metros generales del experimento como:
- `N_SPLITS`: n煤mero de particiones para validaci贸n cruzada.
- `N_ESTIMATORS`: n煤mero de 谩rboles del modelo Random Forest.
- `METRICA_WEIGHTS`: pesos personalizados para m茅tricas.
- `RANDOM_STATE`: semilla para reproducibilidad.

### 3. **Carga de Datos**
Se cargan dos archivos `.csv`:
- Dataset principal: `encavi_reducido_convertido.csv`
- Diccionario de columnas: `diccionario_columnas.csv`

Se realiza una verificaci贸n de existencia y formato correcto de columnas.

### 4. **Renombrado de Columnas**
Utilizando el diccionario cargado, se renombran todas las columnas del dataset original para facilitar su comprensi贸n y an谩lisis.

### 5. **Preprocesamiento**
- Se aplica **One-Hot Encoding** a variables categ贸ricas espec铆ficas (`Sexo`, `fumador`) usando `pd.get_dummies()` con `drop_first=True`.
- Se crea un nuevo DataFrame `df_preprocesado` con las variables codificadas.
- Paralelamente, se genera una copia del DataFrame renombrado (`df_modelo`) para mantener una versi贸n limpia para an谩lisis o visualizaciones adicionales.

### 6. **An谩lisis Exploratorio**
Se analiza el DataFrame renombrado (`df_renombrado`) para obtener:
- Informaci贸n general (`info()`).
- Estad铆sticas descriptivas (`describe()`).
- Conteo de valores nulos por columna.

### 7. **Selecci贸n de Variables y Preparaci贸n del Modelo**
- Se define la variable objetivo (`y`) y las variables predictoras (`X`) a partir del `df_preprocesado`.
- Se crea un conjunto de validaci贸n cruzada estratificada usando `StratifiedKFold`.

### 8. **Balanceo de Clases con SMOTE**
- Se aplica **SMOTE (Synthetic Minority Over-sampling Technique)** dentro del ciclo de validaci贸n cruzada para evitar el desbalance de clases.
- SMOTE se ajusta solamente al conjunto de entrenamiento en cada fold, evitando data leakage.

### 9. **Entrenamiento con Random Forest**
- Se entrena un modelo `RandomForestClassifier` en cada fold del `StratifiedKFold`.
- Se calculan m茅tricas por fold como:
  - Accuracy
  - ROC AUC
  - Precisi贸n, Recall, F1
  - Matriz de confusi贸n

### 10. **Evaluaci贸n Global del Modelo**
- Se realiza un promedio de m茅tricas sobre todos los folds.
- Se pueden visualizar:
  - **Curvas ROC** por fold
  - **Importancia de caracter铆sticas**
  - **Matrices de confusi贸n agregadas**

### 11. **Threshold Personalizado (si aplica)**
- En lugar de usar un umbral est谩ndar de 0.5 para clasificaci贸n, el script puede evaluar otros thresholds basados en la m茅trica combinada ponderada (`METRICA_WEIGHTS`), permitiendo ajustar sensibilidad y especificidad.

### 12. **Visualizaci贸n y An谩lisis Final**
- Se generan gr谩ficos para interpretar resultados, como:
  - Distribuci贸n de probabilidades predichas
  - Comparaciones entre clases reales y predichas
  - Importancia de variables m谩s relevantes

### 13. **Preparaci贸n para Producci贸n o Reutilizaci贸n**
- El c贸digo est谩 estructurado para permitir f谩cil modificaci贸n e integraci贸n de otros modelos o datasets.
- Puede extenderse para an谩lisis por subgrupos (sexo, edad, comuna, etc.).

## И Tecnolog铆as utilizadas

- Python 3
- pandas, matplotlib, seaborn
- scikit-learn
- imbalanced-learn

##  Estructura del proyecto

```
encavi2025RF/
 encavi2025RF.ipynb           # Notebook principal
 data/                        # Aqu铆 se colocan los archivos CSV del proyecto
 requirements.txt             # Librer铆as necesarias
 .gitignore                   # Exclusiones t铆picas
 README.md                    # Este archivo
```

##  C贸mo ejecutar

1. Clona este repositorio.
2. Instala las dependencias:

```bash
pip install -r requirements.txt
```

3. Coloca los archivos CSV (`encavi_reducido_convertido.csv` y `diccionario_columnas.csv`) dentro de la carpeta `data/`.
4. Abre el notebook `encavi2025RF.ipynb` en Jupyter o VSCode.

##  Notas

- El proyecto est谩 estructurado para f谩cil extensibilidad hacia otros modelos (XGBoost, redes neuronales, etc.).
